{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:0, score: 0.0\n",
      "episode:1, score: 1.0\n",
      "episode:2, score: -1.0\n",
      "episode:3, score: 0.0\n",
      "episode:4, score: 0.0\n",
      "episode:5, score: 0.0\n",
      "episode:6, score: -1.0\n",
      "episode:7, score: 0.0\n",
      "episode:8, score: -2.0\n",
      "episode:9, score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 随机走10轮\n",
    "for i in range(10):\n",
    "    env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0                                          # initialize the score\n",
    "    while True:\n",
    "        action = np.random.randint(action_size)        # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "\n",
    "    print(\"episode:{}, score: {}\".format(i, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import objgraph\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "        self.update_freq = 100  # 模型更新频率\n",
    "        self.replay_size = 2000  # 训练集大小\n",
    "        self.replay_queue = deque(maxlen=self.replay_size)\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"创建一个隐藏层为100的神经网络\"\"\"\n",
    "        STATE_DIM, ACTION_DIM = 37, 4\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(100, input_dim=STATE_DIM, activation='relu'),\n",
    "            layers.Dense(ACTION_DIM, activation=\"linear\")\n",
    "        ])\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizers.Adam(0.001))\n",
    "        return model\n",
    "\n",
    "    def act(self, s, epsilon=0.1):\n",
    "        \"\"\"预测动作\"\"\"\n",
    "        # 刚开始时，加一点随机成分，产生更多的状态\n",
    "        if np.random.uniform() < epsilon - self.step * 0.0002:\n",
    "            return np.random.choice([0, 1, 2, 3])\n",
    "        return int(np.argmax(self.model.predict(np.array([s]))[0]))\n",
    "\n",
    "    def save_model(self, file_path='p1_navigation-dqn.h5'):\n",
    "        print('model saved')\n",
    "        self.model.save(file_path)\n",
    "\n",
    "    def remember(self, s, a, next_s, reward):\n",
    "        self.replay_queue.append((s, a, next_s, reward))\n",
    "\n",
    "    def train(self, batch_size=64, lr=1, factor=0.95):\n",
    "        if len(self.replay_queue) < self.replay_size:\n",
    "            return\n",
    "        self.step += 1\n",
    "        # 每 update_freq 步，将 model 的权重赋值给 target_model\n",
    "        if self.step % self.update_freq == 0:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        replay_batch = random.sample(self.replay_queue, batch_size)\n",
    "        s_batch = np.array([replay[0] for replay in replay_batch])\n",
    "        next_s_batch = np.array([replay[2] for replay in replay_batch])\n",
    "\n",
    "        Q = self.model.predict(s_batch)\n",
    "        Q_next = self.target_model.predict(next_s_batch)\n",
    "\n",
    "        # 使用公式更新训练集中的Q值\n",
    "        for i, replay in enumerate(replay_batch):\n",
    "            _, a, _, reward = replay\n",
    "            Q[i][a] = (1 - lr) * Q[i][a] + lr * (reward + factor * np.amax(Q_next[i]))\n",
    "\n",
    "        # 传入网络进行训练        \n",
    "        self.model.fit(s_batch, Q, verbose=0)   \n",
    "        \n",
    "        del Q\n",
    "        del Q_next\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# GPU显存,防止爆显存\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 score: 0.0 max 0.0\n",
      "tuple                        473158   +473158\n",
      "dict                          69542    +69542\n",
      "list                          67278    +67278\n",
      "function                      54690    +54690\n",
      "cell                          14271    +14271\n",
      "weakref                       12214    +12214\n",
      "builtin_function_or_method     8642     +8642\n",
      "Operation                      7528     +7528\n",
      "_InputList                     7528     +7528\n",
      "Tensor                         7524     +7524\n",
      "episode: 1 score: 1.0 max 1.0\n",
      "tuple            903298   +430140\n",
      "list             120074    +52796\n",
      "dict             106258    +36716\n",
      "Tensor            14760     +7236\n",
      "TF_Output         14752     +7236\n",
      "Operation         14764     +7236\n",
      "_InputList        14764     +7236\n",
      "set               10021     +4020\n",
      "Dimension          7102     +3484\n",
      "TraceableStack     6529     +3216\n",
      "episode: 2 score: 2.0 max 2.0\n",
      "tuple           1330229   +426931\n",
      "list             172477    +52403\n",
      "dict             142700    +36442\n",
      "Tensor            21942     +7182\n",
      "TF_Output         21934     +7182\n",
      "Operation         21946     +7182\n",
      "_InputList        21946     +7182\n",
      "set               14011     +3990\n",
      "Dimension         10560     +3458\n",
      "TraceableStack     9721     +3192\n",
      "episode: 3 score: 1.0 max 2.0\n",
      "tuple           1763579   +433350\n",
      "list             225666    +53189\n",
      "dict             179690    +36990\n",
      "Tensor            29232     +7290\n",
      "TF_Output         29224     +7290\n",
      "Operation         29236     +7290\n",
      "_InputList        29236     +7290\n",
      "set               18061     +4050\n",
      "Dimension         14070     +3510\n",
      "TraceableStack    12961     +3240\n",
      "episode: 4 score: 0.0 max 2.0\n",
      "tuple           2190518   +426939\n",
      "list             278068    +52402\n",
      "dict             216132    +36442\n",
      "Tensor            36414     +7182\n",
      "TF_Output         36406     +7182\n",
      "Operation         36418     +7182\n",
      "_InputList        36418     +7182\n",
      "set               22051     +3990\n",
      "Dimension         17528     +3458\n",
      "TraceableStack    16153     +3192\n",
      "episode: 5 score: 0.0 max 2.0\n",
      "tuple           2620658   +430140\n",
      "list             330864    +52796\n",
      "dict             252848    +36716\n",
      "Tensor            43650     +7236\n",
      "TF_Output         43642     +7236\n",
      "Operation         43654     +7236\n",
      "_InputList        43654     +7236\n",
      "set               26071     +4020\n",
      "Dimension         21012     +3484\n",
      "TraceableStack    19369     +3216\n",
      "episode: 6 score: 0.0 max 2.0\n",
      "tuple           3514347   +893689\n",
      "list             442287   +111423\n",
      "dict             331033    +78185\n",
      "Operation         58670    +15016\n",
      "_InputList        58670    +15016\n",
      "Tensor            58650    +15000\n",
      "TF_Output         58610    +14968\n",
      "set               34820     +8749\n",
      "Dimension         28957     +7945\n",
      "TraceableStack    26349     +6980\n",
      "episode: 7 score: 0.0 max 2.0\n",
      "tuple           5233462  +1719115\n",
      "list             660536   +218249\n",
      "dict             484242   +153209\n",
      "Tensor            87618    +28968\n",
      "TF_Output         87578    +28968\n",
      "Operation         87638    +28968\n",
      "_InputList        87638    +28968\n",
      "set               52580    +17760\n",
      "Dimension         45249    +16292\n",
      "TraceableStack    40557    +14208\n",
      "episode: 8 score: 1.0 max 2.0\n",
      "tuple           6973442  +1739980\n",
      "list             881344   +220808\n",
      "dict             639230   +154988\n",
      "Tensor           116937    +29319\n",
      "TF_Output        116897    +29319\n",
      "Operation        116957    +29319\n",
      "_InputList       116957    +29319\n",
      "set               70535    +17955\n",
      "Dimension         61710    +16461\n",
      "TraceableStack    54921    +14364\n",
      "episode: 9 score: 0.0 max 2.0\n",
      "tuple           8718242  +1744800\n",
      "list            1102744   +221400\n",
      "dict             794630   +155400\n",
      "Tensor           146337    +29400\n",
      "TF_Output        146297    +29400\n",
      "Operation        146357    +29400\n",
      "_InputList       146357    +29400\n",
      "set               88535    +18000\n",
      "Dimension         78210    +16500\n",
      "TraceableStack    69321    +14400\n",
      "episode: 10 score: 0.0 max 2.0\n",
      "tuple          10463043  +1744801\n",
      "list            1324144   +221400\n",
      "dict             950030   +155400\n",
      "Tensor           175737    +29400\n",
      "TF_Output        175697    +29400\n",
      "Operation        175757    +29400\n",
      "_InputList       175757    +29400\n",
      "set              106535    +18000\n",
      "Dimension         94710    +16500\n",
      "TraceableStack    83721    +14400\n",
      "episode: 11 score: -2.0 max 2.0\n",
      "tuple          12207851  +1744808\n",
      "list            1545545   +221401\n",
      "dict            1105430   +155400\n",
      "Tensor           205137    +29400\n",
      "TF_Output        205097    +29400\n",
      "Operation        205157    +29400\n",
      "_InputList       205157    +29400\n",
      "set              124535    +18000\n",
      "Dimension        111210    +16500\n",
      "TraceableStack    98121    +14400\n",
      "episode: 12 score: 0.0 max 2.0\n",
      "tuple          13952643  +1744792\n",
      "list            1766944   +221399\n",
      "dict            1260830   +155400\n",
      "Tensor           234537    +29400\n",
      "TF_Output        234497    +29400\n",
      "Operation        234557    +29400\n",
      "_InputList       234557    +29400\n",
      "set              142535    +18000\n",
      "Dimension        127710    +16500\n",
      "TraceableStack   112521    +14400\n",
      "episode: 13 score: 2.0 max 2.0\n",
      "tuple          15697448  +1744805\n",
      "list            1988345   +221401\n",
      "dict            1416231   +155401\n",
      "Tensor           263937    +29400\n",
      "TF_Output        263897    +29400\n",
      "Operation        263957    +29400\n",
      "_InputList       263957    +29400\n",
      "set              160535    +18000\n",
      "Dimension        144210    +16500\n",
      "TraceableStack   126921    +14400\n",
      "episode: 14 score: 0.0 max 2.0\n",
      "tuple          17442243  +1744795\n",
      "list            2209744   +221399\n",
      "dict            1571630   +155399\n",
      "Tensor           293337    +29400\n",
      "TF_Output        293297    +29400\n",
      "Operation        293357    +29400\n",
      "_InputList       293357    +29400\n",
      "set              178535    +18000\n",
      "Dimension        160710    +16500\n",
      "TraceableStack   141321    +14400\n",
      "episode: 15 score: 0.0 max 2.0\n",
      "tuple          19187043  +1744800\n",
      "list            2431145   +221401\n",
      "dict            1727030   +155400\n",
      "Tensor           322737    +29400\n",
      "TF_Output        322697    +29400\n",
      "Operation        322757    +29400\n",
      "_InputList       322757    +29400\n",
      "set              196535    +18000\n",
      "Dimension        177210    +16500\n",
      "TraceableStack   155721    +14400\n",
      "episode: 16 score: 0.0 max 2.0\n",
      "tuple          20931843  +1744800\n",
      "list            2652544   +221399\n",
      "dict            1882430   +155400\n",
      "Tensor           352137    +29400\n",
      "TF_Output        352097    +29400\n",
      "Operation        352157    +29400\n",
      "_InputList       352157    +29400\n",
      "set              214535    +18000\n",
      "Dimension        193710    +16500\n",
      "TraceableStack   170121    +14400\n",
      "episode: 17 score: -1.0 max 2.0\n",
      "tuple          22676642  +1744799\n",
      "list            2873944   +221400\n",
      "dict            2037830   +155400\n",
      "Tensor           381537    +29400\n",
      "TF_Output        381497    +29400\n",
      "Operation        381557    +29400\n",
      "_InputList       381557    +29400\n",
      "set              232535    +18000\n",
      "Dimension        210210    +16500\n",
      "TraceableStack   184521    +14400\n",
      "episode: 18 score: 1.0 max 2.0\n",
      "tuple          24421440  +1744798\n",
      "list            3095344   +221400\n",
      "dict            2193230   +155400\n",
      "Tensor           410937    +29400\n",
      "TF_Output        410897    +29400\n",
      "Operation        410957    +29400\n",
      "_InputList       410957    +29400\n",
      "set              250535    +18000\n",
      "Dimension        226710    +16500\n",
      "TraceableStack   198921    +14400\n",
      "episode: 19 score: 1.0 max 2.0\n",
      "tuple          26166240  +1744800\n",
      "list            3316744   +221400\n",
      "dict            2348630   +155400\n",
      "Tensor           440337    +29400\n",
      "TF_Output        440297    +29400\n",
      "Operation        440357    +29400\n",
      "_InputList       440357    +29400\n",
      "set              268535    +18000\n",
      "Dimension        243210    +16500\n",
      "TraceableStack   213321    +14400\n",
      "episode: 20 score: 0.0 max 2.0\n",
      "tuple          27911042  +1744802\n",
      "list            3538144   +221400\n",
      "dict            2504030   +155400\n",
      "Tensor           469737    +29400\n",
      "TF_Output        469697    +29400\n",
      "Operation        469757    +29400\n",
      "_InputList       469757    +29400\n",
      "set              286535    +18000\n",
      "Dimension        259710    +16500\n",
      "TraceableStack   227721    +14400\n",
      "episode: 21 score: 0.0 max 2.0\n",
      "tuple          29655841  +1744799\n",
      "list            3759544   +221400\n",
      "dict            2659430   +155400\n",
      "Tensor           499137    +29400\n",
      "TF_Output        499097    +29400\n",
      "Operation        499157    +29400\n",
      "_InputList       499157    +29400\n",
      "set              304535    +18000\n",
      "Dimension        276210    +16500\n",
      "TraceableStack   242121    +14400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 22 score: 0.0 max 2.0\n",
      "tuple          31400641  +1744800\n",
      "list            3980944   +221400\n",
      "dict            2814830   +155400\n",
      "Tensor           528537    +29400\n",
      "TF_Output        528497    +29400\n",
      "Operation        528557    +29400\n",
      "_InputList       528557    +29400\n",
      "set              322535    +18000\n",
      "Dimension        292710    +16500\n",
      "TraceableStack   256521    +14400\n",
      "episode: 23 score: 2.0 max 2.0\n",
      "tuple          33145443  +1744802\n",
      "list            4202344   +221400\n",
      "dict            2970230   +155400\n",
      "Tensor           557937    +29400\n",
      "TF_Output        557897    +29400\n",
      "Operation        557957    +29400\n",
      "_InputList       557957    +29400\n",
      "set              340535    +18000\n",
      "Dimension        309210    +16500\n",
      "TraceableStack   270921    +14400\n",
      "episode: 24 score: 0.0 max 2.0\n",
      "tuple          34890243  +1744800\n",
      "list            4423744   +221400\n",
      "dict            3125630   +155400\n",
      "Tensor           587337    +29400\n",
      "TF_Output        587297    +29400\n",
      "Operation        587357    +29400\n",
      "_InputList       587357    +29400\n",
      "set              358535    +18000\n",
      "Dimension        325710    +16500\n",
      "TraceableStack   285321    +14400\n",
      "episode: 25 score: 0.0 max 2.0\n",
      "tuple          36635044  +1744801\n",
      "list            4645145   +221401\n",
      "dict            3281030   +155400\n",
      "Tensor           616737    +29400\n",
      "TF_Output        616697    +29400\n",
      "Operation        616757    +29400\n",
      "_InputList       616757    +29400\n",
      "set              376535    +18000\n",
      "Dimension        342210    +16500\n",
      "TraceableStack   299721    +14400\n",
      "episode: 26 score: -1.0 max 2.0\n",
      "tuple          38379841  +1744797\n",
      "list            4866544   +221399\n",
      "dict            3436430   +155400\n",
      "Tensor           646137    +29400\n",
      "TF_Output        646097    +29400\n",
      "Operation        646157    +29400\n",
      "_InputList       646157    +29400\n",
      "set              394535    +18000\n",
      "Dimension        358710    +16500\n",
      "TraceableStack   314121    +14400\n",
      "episode: 27 score: -1.0 max 2.0\n",
      "tuple          40124640  +1744799\n",
      "list            5087944   +221400\n",
      "dict            3591830   +155400\n",
      "Tensor           675537    +29400\n",
      "TF_Output        675497    +29400\n",
      "Operation        675557    +29400\n",
      "_InputList       675557    +29400\n",
      "set              412535    +18000\n",
      "Dimension        375210    +16500\n",
      "TraceableStack   328521    +14400\n",
      "episode: 28 score: 0.0 max 2.0\n",
      "tuple          41869440  +1744800\n",
      "list            5309344   +221400\n",
      "dict            3747230   +155400\n",
      "Tensor           704937    +29400\n",
      "TF_Output        704897    +29400\n",
      "Operation        704957    +29400\n",
      "_InputList       704957    +29400\n",
      "set              430535    +18000\n",
      "Dimension        391710    +16500\n",
      "TraceableStack   342921    +14400\n",
      "episode: 29 score: 2.0 max 2.0\n",
      "tuple          43614252  +1744812\n",
      "list            5530745   +221401\n",
      "dict            3902630   +155400\n",
      "Tensor           734337    +29400\n",
      "TF_Output        734297    +29400\n",
      "Operation        734357    +29400\n",
      "_InputList       734357    +29400\n",
      "set              448535    +18000\n",
      "Dimension        408210    +16500\n",
      "TraceableStack   357321    +14400\n",
      "episode: 30 score: -1.0 max 2.0\n",
      "tuple          45359041  +1744789\n",
      "list            5752144   +221399\n",
      "dict            4058030   +155400\n",
      "Tensor           763737    +29400\n",
      "TF_Output        763697    +29400\n",
      "Operation        763757    +29400\n",
      "_InputList       763757    +29400\n",
      "set              466535    +18000\n",
      "Dimension        424710    +16500\n",
      "TraceableStack   371721    +14400\n",
      "episode: 31 score: 0.0 max 2.0\n",
      "tuple          47103843  +1744802\n",
      "list            5973544   +221400\n",
      "dict            4213430   +155400\n",
      "Tensor           793137    +29400\n",
      "TF_Output        793097    +29400\n",
      "Operation        793157    +29400\n",
      "_InputList       793157    +29400\n",
      "set              484535    +18000\n",
      "Dimension        441210    +16500\n",
      "TraceableStack   386121    +14400\n",
      "episode: 32 score: 1.0 max 2.0\n",
      "tuple          48848652  +1744809\n",
      "list            6194946   +221402\n",
      "dict            4368830   +155400\n",
      "Tensor           822537    +29400\n",
      "TF_Output        822497    +29400\n",
      "Operation        822557    +29400\n",
      "_InputList       822557    +29400\n",
      "set              502535    +18000\n",
      "Dimension        457710    +16500\n",
      "TraceableStack   400521    +14400\n",
      "episode: 33 score: -2.0 max 2.0\n",
      "tuple          50593444  +1744792\n",
      "list            6416345   +221399\n",
      "dict            4524230   +155400\n",
      "Tensor           851937    +29400\n",
      "TF_Output        851897    +29400\n",
      "Operation        851957    +29400\n",
      "_InputList       851957    +29400\n",
      "set              520535    +18000\n",
      "Dimension        474210    +16500\n",
      "TraceableStack   414921    +14400\n",
      "episode: 34 score: 1.0 max 2.0\n",
      "tuple          52338247  +1744803\n",
      "list            6637745   +221400\n",
      "dict            4679631   +155401\n",
      "Tensor           881337    +29400\n",
      "TF_Output        881297    +29400\n",
      "Operation        881357    +29400\n",
      "_InputList       881357    +29400\n",
      "set              538535    +18000\n",
      "Dimension        490710    +16500\n",
      "TraceableStack   429321    +14400\n",
      "episode: 35 score: 2.0 max 2.0\n",
      "tuple          54083040  +1744793\n",
      "list            6859144   +221399\n",
      "dict            4835030   +155399\n",
      "Tensor           910737    +29400\n",
      "TF_Output        910697    +29400\n",
      "Operation        910757    +29400\n",
      "_InputList       910757    +29400\n",
      "set              556535    +18000\n",
      "Dimension        507210    +16500\n",
      "TraceableStack   443721    +14400\n",
      "episode: 36 score: 1.0 max 2.0\n",
      "tuple          55827840  +1744800\n",
      "list            7080544   +221400\n",
      "dict            4990430   +155400\n",
      "Tensor           940137    +29400\n",
      "TF_Output        940097    +29400\n",
      "Operation        940157    +29400\n",
      "_InputList       940157    +29400\n",
      "set              574535    +18000\n",
      "Dimension        523710    +16500\n",
      "TraceableStack   458121    +14400\n",
      "episode: 37 score: 1.0 max 2.0\n",
      "tuple          57572643  +1744803\n",
      "list            7301944   +221400\n",
      "dict            5145830   +155400\n",
      "Tensor           969537    +29400\n",
      "TF_Output        969497    +29400\n",
      "Operation        969557    +29400\n",
      "_InputList       969557    +29400\n",
      "set              592535    +18000\n",
      "Dimension        540210    +16500\n",
      "TraceableStack   472521    +14400\n",
      "episode: 38 score: 2.0 max 2.0\n",
      "tuple          59317448  +1744805\n",
      "list            7523345   +221401\n",
      "dict            5301231   +155401\n",
      "Tensor           998937    +29400\n",
      "TF_Output        998897    +29400\n",
      "Operation        998957    +29400\n",
      "_InputList       998957    +29400\n",
      "set              610535    +18000\n",
      "Dimension        556710    +16500\n",
      "TraceableStack   486921    +14400\n",
      "episode: 39 score: 2.0 max 2.0\n",
      "tuple          61062244  +1744796\n",
      "list            7744746   +221401\n",
      "dict            5456632   +155401\n",
      "Tensor          1028337    +29400\n",
      "TF_Output       1028297    +29400\n",
      "Operation       1028357    +29400\n",
      "_InputList      1028357    +29400\n",
      "set              628535    +18000\n",
      "Dimension        573210    +16500\n",
      "TraceableStack   501321    +14400\n",
      "episode: 40 score: 1.0 max 2.0\n",
      "tuple          62807048  +1744804\n",
      "list            7966145   +221399\n",
      "dict            5612031   +155399\n",
      "Tensor          1057737    +29400\n",
      "TF_Output       1057697    +29400\n",
      "Operation       1057757    +29400\n",
      "_InputList      1057757    +29400\n",
      "set              646535    +18000\n",
      "Dimension        589710    +16500\n",
      "TraceableStack   515721    +14400\n",
      "episode: 41 score: 4.0 max 4.0\n",
      "tuple          64551841  +1744793\n",
      "list            8187544   +221399\n",
      "dict            5767430   +155399\n",
      "Tensor          1087137    +29400\n",
      "TF_Output       1087097    +29400\n",
      "Operation       1087157    +29400\n",
      "_InputList      1087157    +29400\n",
      "set              664535    +18000\n",
      "Dimension        606210    +16500\n",
      "TraceableStack   530121    +14400\n",
      "episode: 42 score: 0.0 max 4.0\n",
      "tuple          66296643  +1744802\n",
      "list            8408944   +221400\n",
      "dict            5922830   +155400\n",
      "Tensor          1116537    +29400\n",
      "TF_Output       1116497    +29400\n",
      "Operation       1116557    +29400\n",
      "_InputList      1116557    +29400\n",
      "set              682535    +18000\n",
      "Dimension        622710    +16500\n",
      "TraceableStack   544521    +14400\n",
      "episode: 43 score: 3.0 max 4.0\n",
      "tuple          68041443  +1744800\n",
      "list            8630344   +221400\n",
      "dict            6078230   +155400\n",
      "Tensor          1145937    +29400\n",
      "TF_Output       1145897    +29400\n",
      "Operation       1145957    +29400\n",
      "_InputList      1145957    +29400\n",
      "set              700535    +18000\n",
      "Dimension        639210    +16500\n",
      "TraceableStack   558921    +14400\n",
      "episode: 44 score: 8.0 max 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple          69786256  +1744813\n",
      "list            8851743   +221399\n",
      "dict            6233630   +155400\n",
      "Tensor          1175337    +29400\n",
      "TF_Output       1175297    +29400\n",
      "Operation       1175357    +29400\n",
      "_InputList      1175357    +29400\n",
      "set              718535    +18000\n",
      "Dimension        655710    +16500\n",
      "TraceableStack   573321    +14400\n",
      "model saved\n",
      "episode: 45 score: 5.0 max 8.0\n",
      "tuple          71531068  +1744812\n",
      "list            9073143   +221400\n",
      "dict            6389040   +155410\n",
      "Tensor          1204737    +29400\n",
      "TF_Output       1204697    +29400\n",
      "Operation       1204757    +29400\n",
      "_InputList      1204757    +29400\n",
      "set              736536    +18001\n",
      "Dimension        672210    +16500\n",
      "TraceableStack   587721    +14400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3558f2ed4f77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ecc728741af1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, lr, factor)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mQ_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_s_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# 使用公式更新训练集中的Q值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    607\u001b[0m   \u001b[1;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[1;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[0;32m    320\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1238\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \"\"\"\n\u001b[1;32m-> 1240\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m   def interleave(self,\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   3484\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3485\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[1;32m-> 3486\u001b[1;33m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[0;32m   3487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3488\u001b[0m       raise TypeError(\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   2693\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1852\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 1854\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   1855\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   2687\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   2688\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2689\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   2632\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2634\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2635\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2636\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m           optional_features=optional_features)\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    305\u001b[0m       \"\"\"\n\u001b[0;32m    306\u001b[0m       \u001b[0mnum_in_full_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_full_batches\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m       \u001b[0mfirst_k_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum_in_full_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m       first_k_indices = array_ops.reshape(\n\u001b[0;32m    309\u001b[0m           first_k_indices, [num_full_batches, batch_size])\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[1;34m(input_, begin, size, name)\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m   \"\"\"\n\u001b[1;32m--> 866\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(input, begin, size, name)\u001b[0m\n\u001b[0;32m   9222\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9223\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 9224\u001b[1;33m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[0;32m   9225\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9226\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    794\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3429\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3431\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1771\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1772\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1773\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1774\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\drlnd2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 100 # 训练次数\n",
    "score_list = [] # 记录所有训练分数\n",
    "agent = DQN()\n",
    "\n",
    "max_avg_score = 5\n",
    "for i in range(episodes):\n",
    "    gc.collect() # 释放资源,防止爆内存\n",
    "    \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    score = 0\n",
    "    while True:\n",
    "        # print(state)\n",
    "        action = agent.act(state)   \n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "             \n",
    "        agent.remember(state, action, next_state, reward)\n",
    "        agent.train()\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        if done:\n",
    "            score_list.append(score)\n",
    "            print('episode:', i, 'score:', score, 'max', max(score_list))\n",
    "            objgraph.show_growth()\n",
    "            break\n",
    "            \n",
    "    # 保存模型\n",
    "    avg_score = np.max(score_list[-5:])\n",
    "    if avg_score > max_avg_score:\n",
    "        max_avg_score = avg_score\n",
    "        agent.save_model()\n",
    "        # break\n",
    "\n",
    "# 训练结束后关闭环境\n",
    "# env.close()\n",
    "\n",
    "plt.plot(score_list, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证,观看实际效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 score: 1.0\n",
      "episode: 1 score: 7.0\n",
      "episode: 2 score: 0.0\n",
      "episode: 3 score: 2.0\n",
      "episode: 4 score: 5.0\n",
      "episode: 5 score: -1.0\n",
      "episode: 6 score: 1.0\n",
      "episode: 7 score: 4.0\n",
      "episode: 8 score: 0.0\n",
      "episode: 9 score: 1.0\n",
      "10 episode, avg score:2.0\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('p1_navigation-dqn.h5')\n",
    "\n",
    "episodes = 10\n",
    "score_list = []\n",
    "for i in range(episodes):\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0                                          # initialize the score\n",
    "    while True:\n",
    "        action = int(np.argmax(model.predict(np.array([state]))[0]))        # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            score_list.append(score)\n",
    "            print(\"episode:\", i ,\"score:\", score)\n",
    "            break\n",
    "print(\"{} episode, avg score:{}\".format(episodes, np.average(score_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关闭环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
